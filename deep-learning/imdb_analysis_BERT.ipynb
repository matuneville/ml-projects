{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tuning a BERT model for IMDb review classification",
   "id": "c7447cb073492d85"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T23:42:26.811686Z",
     "start_time": "2024-10-20T23:41:49.897563Z"
    }
   },
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import torchtext\n",
    "\n",
    "# from Hugging Face\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from triton.language import dtype"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data preparation\n",
    "### Loading Dataset\n",
    "\n",
    "Already downloaded (for previous Logistic Regression and RNN based models). "
   ],
   "id": "e50d7a96a0411e3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:42:28.845130Z",
     "start_time": "2024-10-20T23:42:26.874593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"../supervised-learning/imdb-review-classification/movie_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.sample(5)"
   ],
   "id": "87652eae8dcc7929",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review  sentiment\n",
       "1876   After seeing Forever Hollywood, it would be na...          0\n",
       "5569   The mod squad gets started 'after' the formati...          0\n",
       "31978  I thought the movie was actually pretty good. ...          1\n",
       "46975  This is a real eye candy. A world made of floa...          1\n",
       "21490  Let me get this straight:<br /><br />\"Hotshot ...          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>After seeing Forever Hollywood, it would be na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>The mod squad gets started 'after' the formati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31978</th>\n",
       "      <td>I thought the movie was actually pretty good. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46975</th>\n",
       "      <td>This is a real eye candy. A world made of floa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21490</th>\n",
       "      <td>Let me get this straight:&lt;br /&gt;&lt;br /&gt;\"Hotshot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sentiment == 1 means positive review, 0 for negatives.  \n",
    "\n",
    "The dataset is balanced:"
   ],
   "id": "744d0ad8815bf610"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:42:29.142932Z",
     "start_time": "2024-10-20T23:42:29.134671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Length of dataset: {df.shape[0]}')\n",
    "print(f'Number of positive and negative reviews: {df[df['sentiment'] == 1].shape[0]}, {df[df['sentiment'] == 0].shape[0]}')"
   ],
   "id": "db412ea250fa44df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 50000\n",
      "Number of positive and negative reviews: 25000, 25000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Splitting Dataset: Train, Validation and Test subsets\n",
    "\n",
    "We will use 70% for training, 10% for validation and 20% for testing."
   ],
   "id": "46feaf2997a8c066"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:42:29.822054Z",
     "start_time": "2024-10-20T23:42:29.187419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=1310)\n",
    "valid_size = df.shape[0] * 0.1\n",
    "valid_frac_in_train_df = valid_size / train_df.shape[0]\n",
    "train_df, valid_df = train_test_split(train_df, test_size=valid_frac_in_train_df, random_state=1310)\n",
    "\n",
    "print(f'Train size: {train_df.shape[0]}')\n",
    "print(f'Valid size: {valid_df.shape[0]}')\n",
    "print(f'Test size: {test_df.shape[0]}')"
   ],
   "id": "e4b2707c9b2f9d80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 35000\n",
      "Valid size: 5000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenizing the dataset\n",
    "\n",
    "We will tokenize the texts into individual word tokens using the tokenizer provided by the pre-trained model class."
   ],
   "id": "d7b2359f7a3251fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:42:48.782757Z",
     "start_time": "2024-10-20T23:42:29.967811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_df['review'].values.tolist(), padding=True, truncation=True)\n",
    "valid_encodings = tokenizer(valid_df['review'].values.tolist(), padding=True, truncation=True)\n",
    "test_encodings = tokenizer(test_df['review'].values.tolist(), padding=True, truncation=True)"
   ],
   "id": "895fff2049b53658",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:42:48.803697Z",
     "start_time": "2024-10-20T23:42:48.797992Z"
    }
   },
   "cell_type": "code",
   "source": "train_encodings[0]",
   "id": "dbcc19ca25711f32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset class and DataLoader",
   "id": "7f469e2cf27ef376"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:43:07.157822Z",
     "start_time": "2024-10-20T23:43:07.144765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        super(IMDbDataset, self).__init__()\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # create a hashmap to hold the input tokens, attention masks and label\n",
    "        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.int32)\n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "id": "298bdafe1dbbac01",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:43:16.949432Z",
     "start_time": "2024-10-20T23:43:16.944954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = IMDbDataset(train_encodings, train_df['sentiment'].values)\n",
    "valid_dataset = IMDbDataset(valid_encodings, valid_df['sentiment'].values)\n",
    "test_dataset = IMDbDataset(test_encodings, test_df['sentiment'].values)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "id": "7792393a032c7c55",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning pre-trained BERT LLM\n",
    "### General settings"
   ],
   "id": "bedf2e945e73b80a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:43:00.888837Z",
     "start_time": "2024-10-20T23:43:00.672349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1310) # for reproducibility\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 3"
   ],
   "id": "a60fb14c73007688",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading the BERT model\n",
    "\n",
    "The downstream task we want to fine-tune the BERT model on is **sequence classification**.  \n",
    "\n",
    "`'distilbert-base-uncased'` is a streamlined, lightweight and uncased version of the BERT base model. It offers a smaller size while maintaining strong performance, making it more computationally efficient for tasks without sacrificing much accuracy."
   ],
   "id": "b92947aadd4372a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T23:46:10.497158Z",
     "start_time": "2024-10-20T23:46:00.706340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "bert_model.to(device)\n",
    "bert_model"
   ],
   "id": "c03e9377ebb59bb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3481387d0c2a404c99c83fba1e05b861"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5fe5f211ff84a6a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
