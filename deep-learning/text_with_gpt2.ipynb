{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T19:43:54.521424Z",
     "start_time": "2024-10-20T19:43:53.824032Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "text_generator = pipeline(task='text-generation', model='gpt2', device='cuda:0')"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T19:46:40.082208Z",
     "start_time": "2024-10-20T19:46:38.914365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_seed(1310)\n",
    "output = text_generator(\"Once upon a time, a dark king called\",\n",
    "               max_length=100,\n",
    "               num_return_sequences=1,\n",
    "               truncation=True)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ],
   "id": "72f40eea8bc332a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a dark king called the Fortunes were defeated, which led to their downfall and the ending of the world. So long as a person can remember the events in History they will remain sane.\n",
      "\n",
      "There is a different story of a time when the gods who brought the world have abandoned them due to their failure and thus they are no longer living and the world is in terrible danger. A few days after the collapse of the world, the gods have gathered together again to\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:02:24.944812Z",
     "start_time": "2024-10-20T20:02:24.534142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "text = 'I will encode this text LOL'\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input "
   ],
   "id": "a90ff4cd2538ed0d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   40,   481, 37773,   428,  2420, 35513]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All words were mapped to an int, and attentiosn masks are all 1, meaning that all words will be processed when we pass the encoded input to the model",
   "id": "ca121a035b626267"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:03:58.697996Z",
     "start_time": "2024-10-20T20:03:58.038726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "output = model(**encoded_input)"
   ],
   "id": "35c4c599ba9ca633",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The output variable stores the last hidden state, that is, our GPT-2-based feature encoding of the input sentence:",
   "id": "fe9236029cd18a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T20:04:10.850253Z",
     "start_time": "2024-10-20T20:04:10.845450Z"
    }
   },
   "cell_type": "code",
   "source": "output['last_hidden_state'].shape",
   "id": "aac50731d245b53f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "batch_size x sentence_length x size_feature_encoding  \n",
    "\n",
    "Now, we could apply this feature encoding to a given dataset and train a downstream classifier based on the GPT-2-based feature representation."
   ],
   "id": "d0e04c554fe6d20f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e933e5d462be585"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
